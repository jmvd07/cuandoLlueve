{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset rain_teodelina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) agregar features que aporten valor al dataset  \n",
    "\n",
    "2) Analizar features data / target \n",
    "\n",
    "3) dividir dataset (training, validation, test)    \n",
    "\n",
    "4) analizar y elegir el modelo mas apropiado, entrenarlo y analizar resultados  \n",
    "\n",
    "5) combinar clasificadores y analizar resultados  \n",
    "\n",
    "6) evaluar predicciones de los diferentes modelos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978-01-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-01-02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-01-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-01-04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-01-05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rain\n",
       "date            \n",
       "1978-01-01     0\n",
       "1978-01-02     0\n",
       "1978-01-03     0\n",
       "1978-01-04     0\n",
       "1978-01-05     0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_t = pd.read_csv(\"rain_teodelina.csv\", parse_dates = [\"date\"], index_col=[0])\n",
    "rain_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15034.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.331914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.451975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rain\n",
       "count  15034.000000\n",
       "mean       3.331914\n",
       "std       11.451975\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max      220.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_t.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count_t = rain_t.isnull().sum()\n",
    "missing_values_count_t[missing_values_count_t > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_t['mes'] = rain_t.index.month\n",
    "rain_t['año'] = rain_t.index.year\n",
    "#lluvias['mesHid'] = (lluvias.index.month+5)%12+1\n",
    "rain_t['añoHid'] = (rain_t.index + dt.timedelta(days=181))\n",
    "rain_t['mesHid'] = rain_t.añoHid.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>mes</th>\n",
       "      <th>año</th>\n",
       "      <th>añoHid</th>\n",
       "      <th>mesHid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15034.000000</td>\n",
       "      <td>15034.000000</td>\n",
       "      <td>15034.000000</td>\n",
       "      <td>15034</td>\n",
       "      <td>15034.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-12-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.331914</td>\n",
       "      <td>6.503193</td>\n",
       "      <td>1998.082413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.526739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.451975</td>\n",
       "      <td>3.456608</td>\n",
       "      <td>11.881857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.442680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rain           mes           año               añoHid  \\\n",
       "count   15034.000000  15034.000000  15034.000000                15034   \n",
       "unique           NaN           NaN           NaN                15034   \n",
       "top              NaN           NaN           NaN  1989-12-27 00:00:00   \n",
       "freq             NaN           NaN           NaN                    1   \n",
       "first            NaN           NaN           NaN  1978-07-01 00:00:00   \n",
       "last             NaN           NaN           NaN  2019-08-28 00:00:00   \n",
       "mean        3.331914      6.503193   1998.082413                  NaN   \n",
       "std        11.451975      3.456608     11.881857                  NaN   \n",
       "min         0.000000      1.000000   1978.000000                  NaN   \n",
       "25%         0.000000      3.250000   1988.000000                  NaN   \n",
       "50%         0.000000      7.000000   1998.000000                  NaN   \n",
       "75%         0.000000     10.000000   2008.000000                  NaN   \n",
       "max       220.000000     12.000000   2019.000000                  NaN   \n",
       "\n",
       "              mesHid  \n",
       "count   15034.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "first            NaN  \n",
       "last             NaN  \n",
       "mean        6.526739  \n",
       "std         3.442680  \n",
       "min         1.000000  \n",
       "25%         4.000000  \n",
       "50%         7.000000  \n",
       "75%        10.000000  \n",
       "max        12.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_t.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "AcumMensual = pd.pivot_table(rain_t, values='rain', index=['año'],columns=['mes'], aggfunc=np.sum, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>mes</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>año</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>217.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>110.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>21.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>297.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>228.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>113.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>203.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>83.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>331.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>96.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>108.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>191.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>141.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>130.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>86.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>219.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>62.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>93.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>121.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>210.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>168.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>140.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>93.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>328.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>41.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>229.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>158.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>92.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>147.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>123.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>69.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>209.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>160.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>115.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>33.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>293.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>235.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>173.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>314.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "mes      1      2      3      4      5      6      7      8      9      10  \\\n",
       "año                                                                          \n",
       "1978  217.0  140.0  204.0   77.0   29.0   16.0   68.0   22.0  303.0  132.0   \n",
       "1979  110.0  173.0  166.0   89.0   14.0   47.0   17.0    9.0   29.0   69.0   \n",
       "1980   21.0  113.0  214.0  174.0   30.0   54.0   11.0    5.0   17.0  173.0   \n",
       "1981  297.0  108.0  179.0   92.0   82.0   35.0   16.0    1.0   47.0  103.0   \n",
       "1982  228.0  199.0  103.0  111.0    3.0   26.0   13.0    0.0  107.0   31.0   \n",
       "1983  113.0  148.0   52.0   86.0   50.0    6.0    5.0   32.0   11.0  202.0   \n",
       "1984  203.0  365.0  113.0   39.0   30.0   12.0   12.0   24.0   74.0  160.0   \n",
       "1985   83.0  149.0   61.0   82.0   62.0    0.0   85.0   36.0   71.0  158.0   \n",
       "1986  331.0   50.0   37.0  139.0   22.0   40.0    6.0   31.0   79.0  150.0   \n",
       "1987   96.0  224.0  121.0   75.0   42.0    4.0   86.0   27.0   11.0  144.0   \n",
       "1988  108.0   69.0  367.0   41.0    0.0    3.0   35.0    0.0   60.0  105.0   \n",
       "1989  191.0  100.0  136.0  107.0   62.0   41.0   34.0   20.0   31.0   59.0   \n",
       "1990  141.0  155.0  261.0  213.0  105.0    0.0   48.0   30.0   77.0  141.0   \n",
       "1991  130.0  162.0  196.0  140.0   70.0  118.0   43.0   68.0   61.0   89.0   \n",
       "1992   86.0   38.0  154.0   81.0   22.0   72.0   18.0   87.0   66.0   60.0   \n",
       "1993  219.0   80.0   94.0  292.0  129.0   87.0    0.0   60.0  100.0  213.0   \n",
       "1994   62.0   87.0   19.0  126.0   57.0   38.0   45.0   41.0   26.0  101.0   \n",
       "1995   93.0   48.0  197.0  238.0   55.0   33.0    6.0    1.0   24.0  161.0   \n",
       "1996  121.0  152.0   61.0  166.0   33.0    0.0    7.0   15.0   36.0   97.0   \n",
       "1997  210.0   56.0   59.0   50.0   96.0   72.0   22.0    9.0   10.0  180.0   \n",
       "1998  168.0  131.0   91.0  174.0  108.0   10.0   56.0   15.0   22.0   84.0   \n",
       "1999  140.0  118.0  330.0  151.0   16.0   34.0   12.0   54.0   40.0  122.0   \n",
       "2000   93.0  177.0  109.0  239.0  298.0   23.0    4.0   52.0   61.0  212.0   \n",
       "2001  328.0   47.0  364.0  151.0   24.0   12.0    7.0  119.0  186.0  289.0   \n",
       "2002  188.0   46.0  208.0   85.0  113.0    6.0   29.0   91.0   17.0  252.0   \n",
       "2003   41.0  202.0  128.0  205.0   37.0   19.0   99.0   24.0   19.0   45.0   \n",
       "2004  229.0   25.0   74.0  142.0   95.0    5.0   71.0   43.0    0.0   89.0   \n",
       "2005  158.0   79.0  144.0   58.0    3.0   18.0   52.0   43.0   54.0   58.0   \n",
       "2006   92.0   82.0   87.0   87.0    9.0   24.0   27.0    0.0   22.0  198.0   \n",
       "2007  147.0  274.0  294.0   64.0   49.0   18.0    7.0    7.0   84.0   81.0   \n",
       "2008  123.0  178.0  122.0    4.0    2.0   22.0   47.0    0.0   56.0   98.0   \n",
       "2009   69.0  118.0   56.0   50.0   45.0    0.0   40.0    5.0  161.0   74.0   \n",
       "2010  209.0  138.0   89.0   45.0   88.0   13.0   10.0    7.0  120.0   89.0   \n",
       "2011  160.0  134.0   87.0  120.0   59.0   16.0    7.0    4.0   24.0  103.0   \n",
       "2012  115.0  288.0  176.0   21.0   80.0    0.0    0.0   83.0   79.0  377.0   \n",
       "2013   33.0   56.0  178.0  110.0  150.0   24.0    0.0    0.0   33.0   68.0   \n",
       "2014  293.0  329.0  154.0  266.0  145.0   64.0   16.0    0.0  142.0  174.0   \n",
       "2015  235.0  167.0  194.0  190.0  116.0   37.0  120.0  255.0   46.0  128.0   \n",
       "2016  173.0  285.0   50.0  368.0   15.0   73.0   23.0    6.0   83.0  178.0   \n",
       "2017  314.0  217.0  286.0  318.0  141.0   30.0   53.0  118.0  170.0  187.0   \n",
       "2018   66.0   60.0   28.0  232.0  167.0   35.0   47.0   74.0   60.0  151.0   \n",
       "\n",
       "mes      11     12  \n",
       "año                 \n",
       "1978  235.0   50.0  \n",
       "1979  190.0  120.0  \n",
       "1980  112.0  107.0  \n",
       "1981  147.0   81.0  \n",
       "1982  133.0   52.0  \n",
       "1983  127.0   40.0  \n",
       "1984  105.0   81.0  \n",
       "1985  147.0   75.0  \n",
       "1986  131.0   16.0  \n",
       "1987  159.0  134.0  \n",
       "1988   26.0   96.0  \n",
       "1989   98.0  172.0  \n",
       "1990  127.0  119.0  \n",
       "1991  111.0  360.0  \n",
       "1992  200.0  115.0  \n",
       "1993   78.0  211.0  \n",
       "1994   41.0  120.0  \n",
       "1995   87.0  182.0  \n",
       "1996  102.0  142.0  \n",
       "1997  115.0  234.0  \n",
       "1998  167.0  116.0  \n",
       "1999   60.0  167.0  \n",
       "2000  214.0   42.0  \n",
       "2001  103.0  154.0  \n",
       "2002  234.0  240.0  \n",
       "2003  101.0  129.0  \n",
       "2004  106.0  209.0  \n",
       "2005  163.0   19.0  \n",
       "2006   67.0  165.0  \n",
       "2007  112.0   89.0  \n",
       "2008  146.0   67.0  \n",
       "2009  191.0  359.0  \n",
       "2010   18.0   63.0  \n",
       "2011   69.0    3.0  \n",
       "2012  172.0  129.0  \n",
       "2013  266.0  131.0  \n",
       "2014  250.0  153.0  \n",
       "2015  202.0  149.0  \n",
       "2016  135.0  346.0  \n",
       "2017   56.0  153.0  \n",
       "2018  138.0  182.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumas_short = AcumMensual.drop(['All'], axis=1)\n",
    "sumas_short = sumas_short.drop([2019,'All'], axis=0)\n",
    "sumas_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = rain_t.rain\n",
    "\n",
    "consecutive_dry = [1 if data == 0 else 0 for data in precipitation]\n",
    "for i in range(1, len(consecutive_dry)):\n",
    "    if consecutive_dry[i] == 1:\n",
    "        consecutive_dry[i] += consecutive_dry[i - 1]\n",
    "        \n",
    "consecutive_wet = [1 if data > 0 else 0 for data in precipitation]\n",
    "for i in range(1, len(consecutive_wet)):\n",
    "    if consecutive_wet[i] == 1:\n",
    "        consecutive_wet[i] += consecutive_wet[i - 1]\n",
    "\n",
    "rain_t['cons_dry'] = consecutive_dry\n",
    "rain_t['cons_wet'] = consecutive_wet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x251b712f898>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_t = rain_t.corr()\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_t, mask=np.zeros_like(corr_t, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset: rain_junin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Aplicar tecnicas de selección y extraccion de features  \n",
    "\n",
    "2) Analizar features data / target \n",
    "\n",
    "3) dividir dataset (training, validation, test)  \n",
    "\n",
    "4) analizar y elegir el modelo mas apropiado, entrenarlo y analizar resultados\n",
    "\n",
    "5) combinar clasificadores y analizar resultados  \n",
    "\n",
    "6) evaluar predicciones de los diferentes modelos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PRCP_ATTRIBUTES</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>SNWD_ATTRIBUTES</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TAVG_ATTRIBUTES</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMAX_ATTRIBUTES</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_ATTRIBUTES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967-05-05</th>\n",
       "      <td>ARM00087548</td>\n",
       "      <td>JUNIN, AR</td>\n",
       "      <td>-34.546</td>\n",
       "      <td>-60.931</td>\n",
       "      <td>79.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.3</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>25.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>11.1</td>\n",
       "      <td>,,S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-05-13</th>\n",
       "      <td>ARM00087548</td>\n",
       "      <td>JUNIN, AR</td>\n",
       "      <td>-34.546</td>\n",
       "      <td>-60.931</td>\n",
       "      <td>79.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>25.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>6.1</td>\n",
       "      <td>,,S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-06-01</th>\n",
       "      <td>ARM00087548</td>\n",
       "      <td>JUNIN, AR</td>\n",
       "      <td>-34.546</td>\n",
       "      <td>-60.931</td>\n",
       "      <td>79.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>,,S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-06-02</th>\n",
       "      <td>ARM00087548</td>\n",
       "      <td>JUNIN, AR</td>\n",
       "      <td>-34.546</td>\n",
       "      <td>-60.931</td>\n",
       "      <td>79.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>12.2</td>\n",
       "      <td>,,S</td>\n",
       "      <td>8.9</td>\n",
       "      <td>,,S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-06-03</th>\n",
       "      <td>ARM00087548</td>\n",
       "      <td>JUNIN, AR</td>\n",
       "      <td>-34.546</td>\n",
       "      <td>-60.931</td>\n",
       "      <td>79.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>11.1</td>\n",
       "      <td>,,S</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>,,S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                STATION       NAME  LATITUDE  LONGITUDE  ELEVATION  PRCP  \\\n",
       "DATE                                                                       \n",
       "1967-05-05  ARM00087548  JUNIN, AR   -34.546    -60.931       79.9   NaN   \n",
       "1967-05-13  ARM00087548  JUNIN, AR   -34.546    -60.931       79.9   NaN   \n",
       "1967-06-01  ARM00087548  JUNIN, AR   -34.546    -60.931       79.9   5.1   \n",
       "1967-06-02  ARM00087548  JUNIN, AR   -34.546    -60.931       79.9   2.0   \n",
       "1967-06-03  ARM00087548  JUNIN, AR   -34.546    -60.931       79.9   0.0   \n",
       "\n",
       "           PRCP_ATTRIBUTES  SNWD SNWD_ATTRIBUTES  TAVG TAVG_ATTRIBUTES  TMAX  \\\n",
       "DATE                                                                           \n",
       "1967-05-05             NaN   NaN             NaN  15.3            H,,S  25.0   \n",
       "1967-05-13             NaN   NaN             NaN  12.4            H,,S  25.0   \n",
       "1967-06-01             ,,S   NaN             NaN   8.9            H,,S   NaN   \n",
       "1967-06-02             ,,S   NaN             NaN   9.7            H,,S  12.2   \n",
       "1967-06-03             ,,S   NaN             NaN   3.9            H,,S  11.1   \n",
       "\n",
       "           TMAX_ATTRIBUTES  TMIN TMIN_ATTRIBUTES  \n",
       "DATE                                              \n",
       "1967-05-05             ,,S  11.1             ,,S  \n",
       "1967-05-13             ,,S   6.1             ,,S  \n",
       "1967-06-01             NaN   7.8             ,,S  \n",
       "1967-06-02             ,,S   8.9             ,,S  \n",
       "1967-06-03             ,,S  -2.2             ,,S  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin = pd.read_csv(\"rain_junin.csv\", parse_dates = [\"DATE\"], index_col=[5])\n",
    "rain_junin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PRCP_ATTRIBUTES</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>SNWD_ATTRIBUTES</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TAVG_ATTRIBUTES</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMAX_ATTRIBUTES</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_ATTRIBUTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17308</td>\n",
       "      <td>17308</td>\n",
       "      <td>1.730800e+04</td>\n",
       "      <td>1.730800e+04</td>\n",
       "      <td>1.730800e+04</td>\n",
       "      <td>9744.000000</td>\n",
       "      <td>9744</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>20</td>\n",
       "      <td>17308.000000</td>\n",
       "      <td>17308</td>\n",
       "      <td>7162.000000</td>\n",
       "      <td>7162</td>\n",
       "      <td>14318.000000</td>\n",
       "      <td>14318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ARM00087548</td>\n",
       "      <td>JUNIN, AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>,,S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>17308</td>\n",
       "      <td>17308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.454600e+01</td>\n",
       "      <td>-6.093100e+01</td>\n",
       "      <td>7.990000e+01</td>\n",
       "      <td>4.008087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.123995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.726236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.855559</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.439601e-11</td>\n",
       "      <td>1.149691e-11</td>\n",
       "      <td>1.006158e-11</td>\n",
       "      <td>12.347039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.96268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.852709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.544230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.148457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.454600e+01</td>\n",
       "      <td>-6.093100e+01</td>\n",
       "      <td>7.990000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.454600e+01</td>\n",
       "      <td>-6.093100e+01</td>\n",
       "      <td>7.990000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.454600e+01</td>\n",
       "      <td>-6.093100e+01</td>\n",
       "      <td>7.990000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.454600e+01</td>\n",
       "      <td>-6.093100e+01</td>\n",
       "      <td>7.990000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.454600e+01</td>\n",
       "      <td>-6.093100e+01</td>\n",
       "      <td>7.990000e+01</td>\n",
       "      <td>341.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION       NAME      LATITUDE     LONGITUDE     ELEVATION  \\\n",
       "count         17308      17308  1.730800e+04  1.730800e+04  1.730800e+04   \n",
       "unique            1          1           NaN           NaN           NaN   \n",
       "top     ARM00087548  JUNIN, AR           NaN           NaN           NaN   \n",
       "freq          17308      17308           NaN           NaN           NaN   \n",
       "mean            NaN        NaN -3.454600e+01 -6.093100e+01  7.990000e+01   \n",
       "std             NaN        NaN  1.439601e-11  1.149691e-11  1.006158e-11   \n",
       "min             NaN        NaN -3.454600e+01 -6.093100e+01  7.990000e+01   \n",
       "25%             NaN        NaN -3.454600e+01 -6.093100e+01  7.990000e+01   \n",
       "50%             NaN        NaN -3.454600e+01 -6.093100e+01  7.990000e+01   \n",
       "75%             NaN        NaN -3.454600e+01 -6.093100e+01  7.990000e+01   \n",
       "max             NaN        NaN -3.454600e+01 -6.093100e+01  7.990000e+01   \n",
       "\n",
       "               PRCP PRCP_ATTRIBUTES        SNWD SNWD_ATTRIBUTES          TAVG  \\\n",
       "count   9744.000000            9744    20.00000              20  17308.000000   \n",
       "unique          NaN               2         NaN               2           NaN   \n",
       "top             NaN             ,,S         NaN             ,,S           NaN   \n",
       "freq            NaN            6601         NaN              17           NaN   \n",
       "mean       4.008087             NaN   145.10000             NaN     16.123995   \n",
       "std       12.347039             NaN   320.96268             NaN      5.852709   \n",
       "min        0.000000             NaN    10.00000             NaN     -0.200000   \n",
       "25%        0.000000             NaN    10.00000             NaN     11.600000   \n",
       "50%        0.000000             NaN    20.00000             NaN     16.400000   \n",
       "75%        1.000000             NaN    37.75000             NaN     20.800000   \n",
       "max      341.900000             NaN  1049.00000             NaN     32.900000   \n",
       "\n",
       "       TAVG_ATTRIBUTES         TMAX TMAX_ATTRIBUTES          TMIN  \\\n",
       "count            17308  7162.000000            7162  14318.000000   \n",
       "unique               1          NaN               2           NaN   \n",
       "top               H,,S          NaN             ,,S           NaN   \n",
       "freq             17308          NaN            7160           NaN   \n",
       "mean               NaN    23.726236             NaN      9.855559   \n",
       "std                NaN     6.544230             NaN      6.148457   \n",
       "min                NaN     6.400000             NaN     -8.000000   \n",
       "25%                NaN    18.600000             NaN      5.200000   \n",
       "50%                NaN    23.900000             NaN     10.200000   \n",
       "75%                NaN    29.000000             NaN     14.800000   \n",
       "max                NaN    42.200000             NaN     25.000000   \n",
       "\n",
       "       TMIN_ATTRIBUTES  \n",
       "count            14318  \n",
       "unique               2  \n",
       "top                ,,S  \n",
       "freq             14316  \n",
       "mean               NaN  \n",
       "std                NaN  \n",
       "min                NaN  \n",
       "25%                NaN  \n",
       "50%                NaN  \n",
       "75%                NaN  \n",
       "max                NaN  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967-05-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-05-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-06-01</th>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-06-02</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-06-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PRCP  SNWD  TAVG  TMAX  TMIN\n",
       "DATE                                    \n",
       "1967-05-05   NaN   NaN  15.3  25.0  11.1\n",
       "1967-05-13   NaN   NaN  12.4  25.0   6.1\n",
       "1967-06-01   5.1   NaN   8.9   NaN   7.8\n",
       "1967-06-02   2.0   NaN   9.7  12.2   8.9\n",
       "1967-06-03   0.0   NaN   3.9  11.1  -2.2"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin = rain_junin.drop(['PRCP_ATTRIBUTES'], axis=1)\n",
    "rain_junin = rain_junin.drop(['STATION'], axis=1)\n",
    "rain_junin = rain_junin.drop(['NAME'], axis=1)\n",
    "rain_junin = rain_junin.drop(['ELEVATION'], axis=1)\n",
    "rain_junin = rain_junin.drop(['LATITUDE'], axis=1)\n",
    "rain_junin = rain_junin.drop(['LONGITUDE'], axis=1)\n",
    "rain_junin = rain_junin.drop(['SNWD_ATTRIBUTES'], axis=1)\n",
    "rain_junin = rain_junin.drop(['TAVG_ATTRIBUTES'], axis=1)\n",
    "rain_junin = rain_junin.drop(['TMAX_ATTRIBUTES'], axis=1)\n",
    "rain_junin = rain_junin.drop(['TMIN_ATTRIBUTES'], axis=1)\n",
    "rain_junin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9744.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>17308.000000</td>\n",
       "      <td>7162.000000</td>\n",
       "      <td>14318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.008087</td>\n",
       "      <td>145.10000</td>\n",
       "      <td>16.123995</td>\n",
       "      <td>23.726236</td>\n",
       "      <td>9.855559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.347039</td>\n",
       "      <td>320.96268</td>\n",
       "      <td>5.852709</td>\n",
       "      <td>6.544230</td>\n",
       "      <td>6.148457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>-8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.75000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>14.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>341.900000</td>\n",
       "      <td>1049.00000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRCP        SNWD          TAVG         TMAX          TMIN\n",
       "count  9744.000000    20.00000  17308.000000  7162.000000  14318.000000\n",
       "mean      4.008087   145.10000     16.123995    23.726236      9.855559\n",
       "std      12.347039   320.96268      5.852709     6.544230      6.148457\n",
       "min       0.000000    10.00000     -0.200000     6.400000     -8.000000\n",
       "25%       0.000000    10.00000     11.600000    18.600000      5.200000\n",
       "50%       0.000000    20.00000     16.400000    23.900000     10.200000\n",
       "75%       1.000000    37.75000     20.800000    29.000000     14.800000\n",
       "max     341.900000  1049.00000     32.900000    42.200000     25.000000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, previo al análisis de Features, se cuantifican el número de datos faltantes para su posterior procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRCP     7564\n",
       "SNWD    17288\n",
       "TMAX    10146\n",
       "TMIN     2990\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count = rain_junin.isnull().sum()\n",
    "missing_values_count[missing_values_count > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los datos son tipo \"int64\" y el número de datos faltantes es elevado en general. Para procesarlos, a continuación realizaremos una interpolación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRCP       2\n",
       "SNWD    7886\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin_clean = rain_junin.interpolate()\n",
    "\n",
    "missing_values_count = rain_junin_clean.isnull().sum()\n",
    "missing_values_count[missing_values_count > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin_clean = rain_junin_clean.fillna(method='bfill')\n",
    "missing_values_count = rain_junin_clean.isnull().sum()\n",
    "missing_values_count[missing_values_count > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existen más datos faltantes. A continuación, realizaremos el análisis de selección de Features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una técnica de análisis de los features más sensibles es aplicar una matriz de correlaciones y plotearlo con un mapa de Heatmap para ayudar en la interpretación de los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x251b6a93400>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = rain_junin_clean.corr()\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRCP', 'SNWD', 'TAVG', 'TMAX', 'TMIN'], dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_junin_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se seleccionarán las features más representativas a partir de \"SelectKBest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DATE'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-1b6f1be1b529>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrain_junin_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PRCP'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#columnas objetivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrain_junin_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PRCP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#columnas independientes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DATE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DATE'] not found in axis\""
     ]
    }
   ],
   "source": [
    "y_orig = rain_junin_clean['PRCP']  #columnas objetivo\n",
    "X_orig = rain_junin_clean.drop('PRCP', axis=1)  #columnas independientes\n",
    "X1 = X_orig.drop('DATE', axis=1)\n",
    "X1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ARM00087548'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-448283f7d2eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#plot graph of feature importances for better visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeat_importances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\.conda\\envs\\diplodatos\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ARM00087548'"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(X1,y_orig)\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X1.columns)\n",
    "feat_importances.nlargest(9).plot(kind='barh')\n",
    "f1 = feat_importances.nlargest(5)\n",
    "plt.show()\n",
    "X2 = X1[f1.index]\n",
    "X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se normalizan los valores anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34605546, 0.23321129, 0.59055116, 0.45137668, 0.52284466],\n",
       "       [0.3748662 , 0.23636884, 0.59276872, 0.47273767, 0.47827757],\n",
       "       [0.33864225, 0.21334461, 0.53505475, 0.40129106, 0.62648815],\n",
       "       ...,\n",
       "       [0.33935722, 0.27148577, 0.58963316, 0.44964831, 0.51115681],\n",
       "       [0.33935722, 0.27148577, 0.58963316, 0.44964831, 0.51115681],\n",
       "       [0.33935722, 0.27148577, 0.58963316, 0.44964831, 0.51115681]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = Normalizer().fit(X2)\n",
    "#scaler = StandardScaler().fit(X2)\n",
    "std_X2 = scaler.transform(X2)\n",
    "std_X2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc_X_train = sc.fit_transform(X_train)\n",
    "sc_X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como arrojaban errores de que no podía ajustarse el algoritmo de regresión lineal o logística a los datos anteriores por ser del tipo flotante, se los redondeó de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = np.around(X2, decimals = 0, out = None)\n",
    "X3 = X3.astype(int)\n",
    "y3 = np.around(y_orig, decimals = 0, out = None)\n",
    "y3 = y3.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los set de train y test se repartieron en 70% y 30% respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into test and train \n",
    "# (we won't be using testing sets here, because of the cross-validation; but it couldn be useful)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.3, random_state=42) ##test_size conviene 0.2???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión Logística dió muy buenos resultados. Cabe resaltar que el accuracy es una métrica de Clasificación y en este caso estamos lidiando con Regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Log Reg:  0.7905001047987451\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=True)\n",
      "The best classifier so far is: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=True)\n",
      "Log Reg tomó 3.96 segundos para 4 configuraciones de parámetros candidatos.\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.791 (std: 0.072)\n",
      "Parametros: {'C': 1.0, 'penalty': 'l2', 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.791 (std: 0.072)\n",
      "Parametros: {'C': 1.0, 'penalty': 'l2', 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 3\n",
      "Scores de validación Medios: 0.789 (std: 0.072)\n",
      "Parametros: {'C': 1.0, 'penalty': 'l1', 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 3\n",
      "Scores de validación Medios: 0.789 (std: 0.072)\n",
      "Parametros: {'C': 1.0, 'penalty': 'l1', 'warm_start': False}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(multi_class = 'auto', random_state = 42)\n",
    "lr_param = {'penalty':('l2', 'l1'), 'C':[1.0], 'warm_start':[True, False]}\n",
    "\n",
    "lr_clf = GridSearchCV(lr, lr_param, cv=5, iid=False)\n",
    "start = time()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "best_lr_clf = lr_clf.best_estimator_\n",
    "print('Best Log Reg: ', lr_clf.best_score_)\n",
    "print(best_lr_clf)\n",
    "results = results.append({'clf': best_lr_clf, 'best_res': lr_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_res'].idxmax()]['clf'])\n",
    "\n",
    "print(\"Log Reg tomó %.2f segundos para %d configuraciones de parámetros candidatos.\"\n",
    "      % (time() - start, len(lr_clf.cv_results_['params'])))\n",
    "for i in range(len(lr_clf.cv_results_['params'])+1):\n",
    "    candidatos = np.flatnonzero(lr_clf.cv_results_['rank_test_score'] == i)\n",
    "    for candidato in candidatos:\n",
    "        print(\"El modelo con el ranking: {0}\".format(i))\n",
    "        print(\"Scores de validación Medios: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  lr_clf.cv_results_['mean_test_score'][candidato],\n",
    "                  lr_clf.cv_results_['std_test_score'][candidato]))\n",
    "        print(\"Parametros: {0}\".format(lr_clf.cv_results_['params'][candidato]))\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Score para entrenamiento: 0.78\n",
      "Score para evaluación: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "lr_clf2 = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
    "          tol=0.0001, verbose=0, warm_start=True)\n",
    "\n",
    "lr_clf2.fit(X_train, y_train)\n",
    "results = results.append({'clf': lr_clf2}, ignore_index=True)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print('Score para entrenamiento: %.2f' % \n",
    "      accuracy_score(y_train, lr_clf2.predict(X_train)))\n",
    "print('Score para evaluación: %.2f' %\n",
    "      accuracy_score(y_test, lr_clf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SGDC score:  0.7899555768405223\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "       max_iter=10000, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "       max_iter=10000, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "GridSearchCV tomó 16.27 segundos para 18 configuraciones de parámetros candidatos.\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.790 (std: 0.066)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'log', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.790 (std: 0.066)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'log', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.790 (std: 0.066)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'log', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 4\n",
      "Scores de validación Medios: 0.779 (std: 0.059)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 5\n",
      "Scores de validación Medios: 0.772 (std: 0.058)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 6\n",
      "Scores de validación Medios: 0.770 (std: 0.069)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 7\n",
      "Scores de validación Medios: 0.757 (std: 0.060)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 8\n",
      "Scores de validación Medios: 0.757 (std: 0.059)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 9\n",
      "Scores de validación Medios: 0.750 (std: 0.057)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 10\n",
      "Scores de validación Medios: 0.749 (std: 0.066)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 11\n",
      "Scores de validación Medios: 0.747 (std: 0.057)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 12\n",
      "Scores de validación Medios: 0.744 (std: 0.054)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 13\n",
      "Scores de validación Medios: 0.743 (std: 0.048)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 14\n",
      "Scores de validación Medios: 0.734 (std: 0.077)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 15\n",
      "Scores de validación Medios: 0.729 (std: 0.050)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 16\n",
      "Scores de validación Medios: 0.702 (std: 0.058)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 17\n",
      "Scores de validación Medios: 0.683 (std: 0.078)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "El modelo con el ranking: 18\n",
      "Scores de validación Medios: 0.672 (std: 0.189)\n",
      "Parametros: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "## Stochastic Gradient\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "#parameters_SGDC = {'loss':('hinge', 'log'), 'max_iter': [10000], 'tol': [0.001]}\n",
    "parameters_SGDC = {'loss':('hinge', 'log'), 'learning_rate':('adaptive', 'optimal', 'invscaling'),\n",
    "              'penalty':('l2', 'l1', 'elasticnet'), 'alpha':[0.0001], 'max_iter': [10000], \n",
    "              'eta0': [0.1], 'tol': [0.001]}\n",
    "SGDC = SGDClassifier(random_state=42)\n",
    "SGDC_clf = GridSearchCV(SGDC, parameters_SGDC, cv=5, iid = False, return_train_score = True)\n",
    "start = time()\n",
    "SGDC_clf.fit(X_train, y_train)\n",
    "best_SGDC_clf = SGDC_clf.best_estimator_\n",
    "\n",
    "print('Best SGDC score: ', SGDC_clf.best_score_)\n",
    "print(best_SGDC_clf)\n",
    "results = results.append({'clf': best_SGDC_clf, 'best_res': SGDC_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_res'].idxmax()]['clf'])\n",
    "print(\"\")\n",
    "\n",
    "print(\"GridSearchCV tomó %.2f segundos para %d configuraciones de parámetros candidatos.\"\n",
    "      % (time() - start, len(SGDC_clf.cv_results_['params'])))\n",
    "for i in range(len(SGDC_clf.cv_results_['params'])+1):\n",
    "    candidatos = np.flatnonzero(SGDC_clf.cv_results_['rank_test_score'] == i)\n",
    "    for candidato in candidatos:\n",
    "        print(\"El modelo con el ranking: {0}\".format(i))\n",
    "        print(\"Scores de validación Medios: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  SGDC_clf.cv_results_['mean_test_score'][candidato],\n",
    "                  SGDC_clf.cv_results_['std_test_score'][candidato]))\n",
    "        print(\"Parametros: {0}\".format(SGDC_clf.cv_results_['params'][candidato]))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Descendent Gradient:\n",
      "Score para entrenamiento: 0.78\n",
      "Score para evaluación: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "SGDC_clf2 = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "                        early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
    "                        l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
    "                        max_iter=10000, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
    "                        penalty='l2', power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
    "                        validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "SGDC_clf2.fit(X_train, y_train)\n",
    "results = results.append({'clf': SGDC_clf2}, ignore_index=True)\n",
    "\n",
    "print('Stochastic Descendent Gradient:')\n",
    "print('Score para entrenamiento: %.2f' % \n",
    "      accuracy_score(y_train, SGDC_clf2.predict(X_train)))\n",
    "print('Score para evaluación: %.2f' %\n",
    "      accuracy_score(y_test, SGDC_clf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Log Reg:  0.1012923186592041\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n",
      "The best classifier so far is: \n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n",
      "Log Reg tomó 0.05 segundos para 1 configuraciones de parámetros candidatos.\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.101 (std: 0.034)\n",
      "Parametros: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "## Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr_param = {}\n",
    "\n",
    "lr_clf = GridSearchCV(lr, lr_param, cv=5, iid=False)\n",
    "start = time()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "best_lr_clf = lr_clf.best_estimator_\n",
    "print('Best Log Reg: ', lr_clf.best_score_)\n",
    "print(best_lr_clf)\n",
    "results = results.append({'clf': best_lr_clf, 'best_res': lr_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_res'].idxmax()]['clf'])\n",
    "\n",
    "print(\"Log Reg tomó %.2f segundos para %d configuraciones de parámetros candidatos.\"\n",
    "      % (time() - start, len(lr_clf.cv_results_['params'])))\n",
    "for i in range(len(lr_clf.cv_results_['params'])+1):\n",
    "    candidatos = np.flatnonzero(lr_clf.cv_results_['rank_test_score'] == i)\n",
    "    for candidato in candidatos:\n",
    "        print(\"El modelo con el ranking: {0}\".format(i))\n",
    "        print(\"Scores de validación Medios: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  lr_clf.cv_results_['mean_test_score'][candidato],\n",
    "                  lr_clf.cv_results_['std_test_score'][candidato]))\n",
    "        print(\"Parametros: {0}\".format(lr_clf.cv_results_['params'][candidato]))\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree:  0.05335172153439301\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: 0.053 (std: 0.166)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 2, 'min_samples_split': 5, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 2\n",
      "Scores de validación Medios: 0.030 (std: 0.191)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 3, 'min_samples_split': 19, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 3\n",
      "Scores de validación Medios: 0.003 (std: 0.102)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 1, 'min_samples_split': 21, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 4\n",
      "Scores de validación Medios: 0.001 (std: 0.271)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 3, 'min_samples_split': 23, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 4\n",
      "Scores de validación Medios: 0.001 (std: 0.271)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 3, 'min_samples_split': 2, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 6\n",
      "Scores de validación Medios: -0.015 (std: 0.244)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 6, 'min_samples_split': 20, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 7\n",
      "Scores de validación Medios: -0.018 (std: 0.265)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 22, 'min_samples_split': 23, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 8\n",
      "Scores de validación Medios: -0.029 (std: 0.157)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 4, 'min_samples_split': 8, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 9\n",
      "Scores de validación Medios: -0.044 (std: 0.174)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 4, 'min_samples_split': 21, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 10\n",
      "Scores de validación Medios: -0.046 (std: 0.174)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 4, 'min_samples_split': 18, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 10\n",
      "Scores de validación Medios: -0.046 (std: 0.174)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 4, 'min_samples_split': 13, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 12\n",
      "Scores de validación Medios: -0.061 (std: 0.296)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 17, 'min_samples_split': 17, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 13\n",
      "Scores de validación Medios: -0.095 (std: 0.371)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 17, 'min_samples_split': 11, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 14\n",
      "Scores de validación Medios: -0.109 (std: 0.399)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 14, 'min_samples_split': 10, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 15\n",
      "Scores de validación Medios: -0.111 (std: 0.358)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 5, 'min_samples_split': 23, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 16\n",
      "Scores de validación Medios: -0.115 (std: 0.358)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 5, 'min_samples_split': 22, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 17\n",
      "Scores de validación Medios: -0.124 (std: 0.484)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 21, 'min_samples_split': 6, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 18\n",
      "Scores de validación Medios: -0.129 (std: 0.468)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 12, 'min_samples_split': 9, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 19\n",
      "Scores de validación Medios: -0.152 (std: 0.523)\n",
      "Parametros: {'bootstrap': True, 'max_depth': 16, 'min_samples_split': 5, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 20\n",
      "Scores de validación Medios: -0.189 (std: 0.461)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 22, 'min_samples_split': 17, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 21\n",
      "Scores de validación Medios: -0.193 (std: 0.458)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 9, 'min_samples_split': 22, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 22\n",
      "Scores de validación Medios: -0.196 (std: 0.458)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 8, 'min_samples_split': 17, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 23\n",
      "Scores de validación Medios: -0.215 (std: 0.418)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 5, 'min_samples_split': 8, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 24\n",
      "Scores de validación Medios: -0.310 (std: 0.599)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 24, 'min_samples_split': 15, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 25\n",
      "Scores de validación Medios: -0.720 (std: 1.776)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 6, 'min_samples_split': 11, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 26\n",
      "Scores de validación Medios: -0.872 (std: 1.956)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 9, 'min_samples_split': 11, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 27\n",
      "Scores de validación Medios: -0.903 (std: 1.980)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 20, 'min_samples_split': 10, 'warm_start': False}\n",
      "\n",
      "El modelo con el ranking: 28\n",
      "Scores de validación Medios: -0.965 (std: 1.909)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 8, 'min_samples_split': 7, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 29\n",
      "Scores de validación Medios: -1.541 (std: 2.424)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 11, 'min_samples_split': 2, 'warm_start': True}\n",
      "\n",
      "El modelo con el ranking: 30\n",
      "Scores de validación Medios: -1.550 (std: 2.408)\n",
      "Parametros: {'bootstrap': False, 'max_depth': 16, 'min_samples_split': 2, 'warm_start': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "## Random Forest - Regression\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR #Javier: Leer y probar otros parámetros.\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "tree_param_dist = {'max_depth': sp_randint(1, 25),\n",
    "#                    'max_features': sp_randint(4, 10),\n",
    "                   'min_samples_split': sp_randint(2, 25),\n",
    "                   'bootstrap': [True, False],\n",
    "                   'warm_start': [True, False],}\n",
    "#                    'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# tree_param_dist = {}\n",
    "tree = RFR(random_state=42, n_estimators=30, min_samples_leaf=1)\n",
    "\n",
    "tree_clf = RandomizedSearchCV(tree, param_distributions=tree_param_dist, n_iter=30, cv=10, iid=False) \n",
    "\n",
    "# start = time()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "best_tree_clf = tree_clf.best_estimator_\n",
    "print('Best Decision Tree: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_res': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_res'].idxmax()]['clf'])\n",
    "\n",
    "# print(\"Regression Tree tomó %.2f segundos para %d configuraciones de parámetros candidatos.\"\n",
    "#       % (time() - start, len(tree_clf.cv_results_['params'])))\n",
    "for i in range(len(tree_clf.cv_results_['params'])+1):\n",
    "    candidatos = np.flatnonzero(tree_clf.cv_results_['rank_test_score'] == i)\n",
    "    for candidato in candidatos:\n",
    "        print(\"El modelo con el ranking: {0}\".format(i))\n",
    "        print(\"Scores de validación Medios: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  tree_clf.cv_results_['mean_test_score'][candidato],\n",
    "                  tree_clf.cv_results_['std_test_score'][candidato]))\n",
    "        print(\"Parametros: {0}\".format(tree_clf.cv_results_['params'][candidato]))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=30. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\javi\\.conda\\envs\\diplodatos\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear SVR:  -0.05178930393254115\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     random_state=42, tol=0.0001, verbose=0)\n",
      "The best classifier so far is: \n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     random_state=42, tol=0.0001, verbose=0)\n",
      "Linear SVC tomó 0.21 segundos para 1 configuraciones de parámetros candidatos.\n",
      "El modelo con el ranking: 1\n",
      "Scores de validación Medios: -0.052 (std: 0.035)\n",
      "Parametros: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('clf', 'best_res'))\n",
    "\n",
    "## Linear SVC\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsvr = LinearSVR(random_state=42)\n",
    "lsvr_param = {}\n",
    "\n",
    "lsvr_clf = RandomizedSearchCV(lsvc, lsvc_param, n_iter=30, cv=5, iid=False)\n",
    "start = time()\n",
    "lsvr_clf.fit(X_train, y_train)\n",
    "best_lsvr_clf = lsvr_clf.best_estimator_\n",
    "print('Best Linear SVR: ', lsvr_clf.best_score_)\n",
    "print(best_lsvr_clf)\n",
    "results = results.append({'clf': best_lsvr_clf, 'best_res': lsvr_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_res'].idxmax()]['clf'])\n",
    "\n",
    "print(\"Linear SVC tomó %.2f segundos para %d configuraciones de parámetros candidatos.\"\n",
    "      % (time() - start, len(lsvr_clf.cv_results_['params'])))\n",
    "for i in range(len(lsvr_clf.cv_results_['params'])+1):\n",
    "    candidatos = np.flatnonzero(lsvr_clf.cv_results_['rank_test_score'] == i)\n",
    "    for candidato in candidatos:\n",
    "        print(\"El modelo con el ranking: {0}\".format(i))\n",
    "        print(\"Scores de validación Medios: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  lsvr_clf.cv_results_['mean_test_score'][candidato],\n",
    "                  lsvr_clf.cv_results_['std_test_score'][candidato]))\n",
    "        print(\"Parametros: {0}\".format(lsvr_clf.cv_results_['params'][candidato]))\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinacion de datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Combinar ambos datasets a partir de features comunes a ambos\n",
    "\n",
    "2) Validar la correcctitud de los datos fusionados\n",
    "\n",
    "3) Aplicar tecnicas de selección y extraccion de features  \n",
    "\n",
    "4) Analizar features data / target \n",
    "\n",
    "5) dividir dataset (training, validation, test)  \n",
    "\n",
    "6) analizar y elegir el modelo mas apropiado, entrenarlo y analizar resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
